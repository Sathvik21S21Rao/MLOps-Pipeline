- hosts: local
  connection: local
  gather_facts: true
  vars:
    # Example models list. Update with your real models or pass via --extra-vars.
    # Kubernetes namespace to use for created resources (can be overridden via --extra-vars)
    k8s_namespace: default
    models:
      - name: bert-bert-uncased
        processed_data_path: ../output_data/bert-bert-uncased
        model_checkpoint: bert-base-uncased
        model_output_dir: ../model_output/bert-bert-uncased
  

  tasks:
    - name: Ensure deploy envs directory exists
      file:
        path: ./deploy/envs
        state: directory
        mode: '0755'

    - name: Render per-model env file
      template:
        src: ../templates/env.j2
        dest: ./deploy/envs/{{ item.name }}.env
        mode: '0644'
      loop: "{{ models }}"

    - name: Ensure deploy manifests directory exists
      file:
        path: ./deploy/manifests
        state: directory
        mode: '0755'

    - name: Create a Kubernetes Secret for HF token from vault
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: hf-token
            namespace: "{{ k8s_namespace }}"
          type: Opaque
          stringData:
            HF_API_TOKEN: "{{ hf_api_token }}"

    - name: Create PersistentVolumeClaim for processed data
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: processed-data-pvc
            namespace: "{{ k8s_namespace }}"
          spec:
            accessModes: [ "ReadWriteOnce" ]
            resources:
              requests:
                storage: 5Gi
            # storageClassName: standard  # Uncomment/change if your cluster requires a specific StorageClass

    - name: Create DataLoader Job to populate PVC
      k8s:
        state: present
        definition:
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: dataloader-job
            namespace: "{{ k8s_namespace }}"
          spec:
            backoffLimit: 1
            template:
              spec:
                containers:
                  - name: dataloader
                    image: Nihonium/dataloader:latest
                    command: ["python","DataLoading/data_loading.py"]
                    env:
                      - name: PROCESSED_DATA_PATH
                        value: "/data/output_folder"
                      - name: HF_API_TOKEN
                        valueFrom:
                          secretKeyRef:
                            name: hf-token
                            key: HF_API_TOKEN
                    volumeMounts:
                      - name: processed-data
                        mountPath: /data
                restartPolicy: Never
                volumes:
                  - name: processed-data
                    persistentVolumeClaim:
                      claimName: processed-data-pvc

    - name: Wait for DataLoader Job completion
      k8s_info:
        kind: Job
        namespace: "{{ k8s_namespace }}"
        name: dataloader-job
      register: dl_job_info
      until: dl_job_info.resources | length > 0 and dl_job_info.resources[0].status.succeeded is defined and dl_job_info.resources[0].status.succeeded > 0
      retries: 30
      delay: 10

    - name: Create ConfigMap for model env
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: "{{ model.name }}-env"
            namespace: default
          data:
            PROCESSED_DATA_PATH: "{{ model.processed_data_path }}"
            MODEL_CHECKPOINT: "{{ model.model_checkpoint }}"
            MODEL_OUTPUT_DIR: "{{ model.model_output_dir }}"
            LOGSTASH_HOST: "logstash"
            LOGSTASH_PORT: "5000"
      loop: "{{ models }}"
      loop_control:
        loop_var: model

    - name: Render trainer deployment manifest for model
      template:
        src: ../templates/trainer-deployment.yaml.j2
        dest: ./deploy/manifests/{{ model.name }}-trainer.yaml
      loop: "{{ models }}"
      loop_control:
        loop_var: model

    - name: Apply trainer manifest to Kubernetes
      k8s:
        state: present
        namespace: "{{ k8s_namespace }}"
        src: ./deploy/manifests/{{ model.name }}-trainer.yaml
      loop: "{{ models }}"
      loop_control:
        loop_var: model

